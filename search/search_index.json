{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Detecting and dissecting anomalous anatomic regions in spatial transcriptomics with STANDS","text":"<p>We introduce Spatial Transcriptomics ANomaly Detection and Subtyping (STANDS), an innovative computational method capable of integrating multimodal information, e.g., spatial gene expression, histology image and single cell gene expression, to not only delineate anomalous tissue regions but also reveal their compositional heterogeneities across multi-sample spatial transcriptomics (ST) data. </p> <p></p>"},{"location":"#outline-of-ddatd","title":"Outline of DDATD","text":"<p>The accurate detection of anomalous anatomic regions, followed by their dissection into biologically heterogeneous subdomains across multiple tissue slices, is of paramount importance in clinical diagnostics, targeted therapies and biomedical research. This procedure, which we refer to as Detection and Dissection of Anomalous Tissue Domains (DDATD), serves as the first and foremost step in a comprehensive analysis of tissues harvested from affected individuals for revealing population-level and individual-specific factors (e.g., pathogenic cell types) associated with disease developments. </p> <p></p>"},{"location":"#framework-of-stands","title":"Framework of STANDS","text":"<p>STANDS is an innovative framework built on a suite of specialized Generative Adversarial Networks (GANs) for seamlessly integrating the three tasks of DDATD. The framework consists of three components. Component I (C1) trains a GAN model on the reference dataset, learning to reconstruct normal spots from their multimodal representations of both spatial transcriptomics data and associated histology image. Subsequently, the model is applied on the target datasets to identify anomalous spots as those with unexpectedly large reconstruction deviances, namely anomaly scores. Component II (C2) aims at diminishing the non-biological variations (e.g. batch effects) among anomalies via aligning target datasets in a common space. It employs two cooperative GAN models to identify pairs of reference and target spots that share similar biological contents, based on which the target datasets are aligned to the reference data space via \u201cstyle-transfer\u201d. Component III (C3) fuses the embeddings and reconstruction residuals of aligned anomalous spots to serve as inputs to an iterative clustering algorithm which groups anomalies into distinct subtypes.  </p> <p></p>"},{"location":"#source-codes","title":"Source codes","text":"<p>All the source codes of STANDS are available on STANDS.</p>"},{"location":"#contributors","title":"Contributors","text":"<ul> <li>Kaichen Xu: Lead Developer, implement STANDS and designed this website.</li> <li>Yan Lu: Developer, implement the novel Gaussian Mixture Model.</li> <li>Yihang Du: Developer, implement the Spatial Grouping Discrepancy metrics.</li> <li>Kainan Liu: Developer, diverse contributions.</li> <li>Xiaobo Sun &amp; lab: enabling guidance, support and environment.</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>Coming soon.</p>"},{"location":"start/","title":"Preparation","text":"<p>STANDS is a powerful documentation framework to detect, align and subtyping anomalous tissue domains across multiple samples. In the subsequent sections, we will introduce the preparatory tasks before utilizing STANDS for your research, including the installation of Python packages, downloading of datasets, and other related procedures.</p>"},{"location":"start/#installation","title":"Installation","text":"<p>STANDS is developed as a Python package. You will need to install Python, and the recommended version is Python 3.9.5.</p> <p>You can download the package from GitHub and install it locally:</p> <pre><code>git clone https://github.com/Catchxu/STANDS.git\ncd STANDS/\npython3 setup.py install --user\n</code></pre>"},{"location":"start/#datasets","title":"Datasets","text":"<p>All experimental datasets involved in this paper are available from their respective original sources: the 10x-Visium datasets of healthy human breast tissues (10x-hNB datasets) are available at the CELLxGENE; The 10x-Visium datasets of human breast cancer tissues (10x-hBC datasets) are available at the github; The scRNA-seq dataset of human pancreatic ductal (sc-hPD) and 10x-Visium datasets of the human pancreatic ductal adenocarcinomas (10x-hPDAC) are available at the Gene Expression Omnibus; The slide-seqV2 datasets of mouse embryo tissues (ssq-mEmb datasets) are available at the CELLxGENE.</p> <p>We also provide organized and processed datasets for download.</p>"},{"location":"start/#getting-help","title":"Getting help","text":"<p>See the tutorial for more complete documentation of all the functions of STANDS.</p> <p>For questions or comments, please use the GitHub issues.</p>"},{"location":"start/#tested-environment","title":"Tested environment","text":"<ul> <li>CPU: Intel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz</li> <li>CPU Memory: 256 GB</li> <li>GPU: NVIDIA GeForce RTX 3090 </li> <li>GPU Memory: 24 GB</li> <li>System: Ubuntu 20.04.5 LTS</li> <li>Python: 3.9.15</li> </ul>"},{"location":"start/#main-dependencies","title":"Main Dependencies","text":"<ul> <li>torch==1.13.0</li> <li>dgl==1.1.1</li> <li>torchvision==0.14.1</li> <li>anndata==0.10.3</li> <li>numpy==1.19.2</li> <li>scanpy==1.9.6</li> <li>scipy==1.9.3</li> <li>sklearn==0.0.post2</li> <li>pandas==1.5.2</li> <li>squidpy==1.2.2</li> <li>setuptools==59.5.0</li> </ul>"}]}